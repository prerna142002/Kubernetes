Consensus
1. Agreement on shared state ( single system image)
2. Reconvers from server failures autonomously.
3. Key to building consistent storage systems.

Inside a Consistent System
1. TODO: eliminate single ppoint of failure.

REPLICATE STATE MACHINE
This is used to build Replicated State Machine build in large Systems

PAXOS PROTOCOL
The dirty little secret of the NSDI community is that most five people really, truly understand every part of Paxos.

So, designed RAFT -
We wanted the best algorithm for building real systems.
1. Must be correct, complete and perform well
2. Must also be understandable.

What would be easier to understand or explain
1. Fundamentally different decompisition than Paxos.
2. less complexity in state space.
3. Less mechanism.

RAFT Overview:
1. Leader election -
  a. Select one of the servers to act as cluster leader.
  b. Detect crashes, chose new leeader.

The 1st to timeout will ask for vote to elect itself as leader and vote itself also.
Split Votes:
In this case what happens is that 2 candidates have same timeout so when they ask for votes then they dont win usually becuase
of incomplete votes so we wait for next timeout and then we wait and the timeout is randomized so it becomes easier.


2. Log replication (normal operation)
  a. Leader takes commands from clients, appends them to its log.
  b. Leader replicated its log to other servers (overwriting inconsistencies)

ARROW - Next index - Position in the log where the leader will send the next entry to that server and to make progress you want
that to be point where they diverge
DOT - Match index - Leader knows that it and the follower agree all the way up through the dot so here agree up through
that 1st enrty and the leader knows to send the seond entry next that's actually what the message is about to do.



3. Safety
  a. Only a server with an up-to-date log can become leader.

